"""
Tests that features that are currently unsupported in
either the Python or C parser are actually enforced
and are clearly communicated to the user.

"""
from io import StringIO
import os
from pathlib import Path


from pandas.errors import ParserError


from pandas.io.parsers import read_csv
import pandas.io.parsers.readers as parsers

    "ignore:Passing a BlockManager to DataFrame:DeprecationWarning"
)


def python_engine(request):
    return request.param


class TestUnsupportedFeatures:
        # see gh-12935
        data = "a b c\n1 2 3"

        for engine in ("c", "python"):
                read_csv(StringIO(data), engine=engine, mangle_dupe_cols=True)

        # see gh-6607
        data = "a b c\n1 2 3"
        msg = "does not support"

        depr_msg = "The 'delim_whitespace' keyword in pd.read_csv is deprecated"

        # specify C engine with unsupported options (raise)
            with tm.assert_produces_warning(FutureWarning, match=depr_msg):
                read_csv(StringIO(data), engine="c", sep=None, delim_whitespace=False)
            read_csv(StringIO(data), engine="c", sep=r"\s")
            read_csv(StringIO(data), engine="c", sep="\t", quotechar=chr(128))
            read_csv(StringIO(data), engine="c", skipfooter=1)

        # specify C-unsupported options without python-unsupported options
        with tm.assert_produces_warning((parsers.ParserWarning, FutureWarning)):
            read_csv(StringIO(data), sep=None, delim_whitespace=False)
        with tm.assert_produces_warning(parsers.ParserWarning):
            read_csv(StringIO(data), sep=r"\s")
        with tm.assert_produces_warning(parsers.ParserWarning):
            read_csv(StringIO(data), sep="\t", quotechar=chr(128))
        with tm.assert_produces_warning(parsers.ParserWarning):
            read_csv(StringIO(data), skipfooter=1)

        text = """                      A       B       C       D        E
one two three   four
a   b   10.0032 5    -0.5109 -2.3358 -0.4645  0.05076  0.3640
a   q   20      4     0.4473  1.4152  0.2834  1.00661  0.1744
x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
        msg = "Error tokenizing data"

            read_csv(StringIO(text), sep="\\s+")
            read_csv(StringIO(text), engine="c", sep="\\s+")

        msg = "Only length-1 thousands markers supported"
        data = """A|B|C
1|2,334|5
10|13|10.
"""
            read_csv(StringIO(data), thousands=",,")
            read_csv(StringIO(data), thousands="")

        msg = "Only length-1 line terminators supported"
        data = "a,b,c~~1,2,3~~4,5,6"
            read_csv(StringIO(data), lineterminator="~~")

        from pandas.io.parsers.readers import _python_unsupported as py_unsupported

        data = """1,2,3,,
1,2,3,4,
1,2,3,4,5
1,2,,,
1,2,3,4,"""

        for default in py_unsupported:
            msg = (
                f"The {repr(default)} option is not "
                f"supported with the {repr(python_engine)} engine"
            )

            kwargs = {default: object()}
                read_csv(StringIO(data), engine=python_engine, **kwargs)

        # see gh-16530
        class NoNextBuffer:
            def __init__(self, csv_data) -> None:
                self.data = csv_data

            def __next__(self):
                return self.data.__next__()

            def read(self):
                return self.data

            def readline(self):
                return self.data

        data = "a\n1"
        msg = "'NoNextBuffer' object is not iterable|argument 1 must be an iterator"

            read_csv(NoNextBuffer(data), engine=python_engine)

        from pandas.io.parsers.readers import _pyarrow_unsupported as pa_unsupported

        data = """1,2,3,,
        1,2,3,4,
        1,2,3,4,5
        1,2,,,
        1,2,3,4,"""

        for default in pa_unsupported:
            msg = (
                f"The {repr(default)} option is not "
                f"supported with the 'pyarrow' engine"
            )
            kwargs = {default: object()}
            default_needs_bool = {"warn_bad_lines", "error_bad_lines"}
            if default == "dialect":
            elif default in default_needs_bool:
                kwargs[default] = True
            elif default == "on_bad_lines":
                kwargs[default] = "warn"

            warn = None
            depr_msg = None
            if "delim_whitespace" in kwargs:
                depr_msg = "The 'delim_whitespace' keyword in pd.read_csv is deprecated"
                warn = FutureWarning
            if "verbose" in kwargs:
                depr_msg = "The 'verbose' keyword in pd.read_csv is deprecated"
                warn = FutureWarning

                with tm.assert_produces_warning(warn, match=depr_msg):
                    read_csv(StringIO(data), engine="pyarrow", **kwargs)

        # GH 5686
        # GH 54643
        sio = StringIO("a,b\n1,2")
        bad_lines_func = lambda x: x
        parser = all_parsers
        if all_parsers.engine not in ["python", "pyarrow"]:
            msg = (
                "on_bad_line can only be a callable "
                "function if engine='python' or 'pyarrow'"
            )
                parser.read_csv(sio, on_bad_lines=bad_lines_func)
        else:
            parser.read_csv(sio, on_bad_lines=bad_lines_func)


    # GH 45384
    parser = all_parsers

    error = ValueError
    if parser.engine == "pyarrow":
        # Raises pyarrow.lib.ArrowKeyError

        Path(fname).write_text("col1,col2\na,b\n1,2", encoding="utf-8")
        with tm.assert_produces_warning(False):
                parser.read_csv(fname, usecols=["col1", "col2", "col3"])
        # unlink fails on windows if file handles still point to it
        os.unlink(fname)


    # GH#45957
    parser = all_parsers
    if parser.engine == "python":
        request.applymarker(
        )

        parser.read_csv([])


    parser = all_parsers
    msg = (
        "dtype_backend numpy is invalid, only 'numpy_nullable' and "
        "'pyarrow' are allowed."
    )
